{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import seed, sample\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class Loader():\n",
    "\n",
    "    def __init__(self, in_path, out_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_path (str): csv input path.\n",
    "            out_path (str): Output directory path to store the pickles.\n",
    "            chunksize (int, optional): Chunksize for DataFrame reader. Defaults to 10**6. \n",
    "        \"\"\"\n",
    "\n",
    "        self.__in_path = in_path\n",
    "        self.__out_path = out_path\n",
    "        self.__chunksize = 10**6\n",
    "\n",
    "    def __produce_pickles(self):\n",
    "        \"\"\"produce pickles by reading csv by chunksize\n",
    "        \"\"\"\n",
    "        with pd.read_csv(self.__in_path, chunksize = self.__chunksize) as reader:\n",
    "            try:\n",
    "                os.makedirs(self.__out_path)\n",
    "            except FileExistsError:\n",
    "                # directory already exists\n",
    "                pass\n",
    "            for i, chunk in enumerate(reader):\n",
    "                out_file = self.__out_path + \"/data_{}.pkl\".format(i+1)\n",
    "                with open(out_file, \"wb\") as f:\n",
    "                    pickle.dump(chunk, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def load_pickle(self, pickle_id):\n",
    "        \"\"\"load a pickle file by id\n",
    "\n",
    "        Args:\n",
    "            pickle_id (int): pickle id.\n",
    "\n",
    "        Raises:\n",
    "            Exception: The path of the given id isn't a file\n",
    "\n",
    "        Returns:\n",
    "            obj: DataFrame\n",
    "        \"\"\"\n",
    "        # produce the pickles if the directory not exists or\n",
    "        # if the directory is empty \n",
    "        if (not os.path.exists(self.__out_path)) or \\\n",
    "              (len(os.listdir(self.__out_path)) == 0):\n",
    "            self.__produce_pickles()\n",
    "        \n",
    "        # get the file path following the pickle_id\n",
    "        # given in parameter\n",
    "        file_path = self.__out_path + \\\n",
    "            \"/data_\" + str(pickle_id) + \".pkl\"\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            df = pd.read_pickle(file_path)\n",
    "        else:\n",
    "            raise Exception(\"The pickle file data_{}.pkl doesn't exist\".format(pickle_id))\n",
    "        return df\n",
    "        \n",
    "\n",
    "    def random_pickles(self, n_pickles = 3, init = 42, verbose = True):\n",
    "        \"\"\"random reader over pickles files\n",
    "\n",
    "        Args:\n",
    "            n_pickles (int, optional): number of pickles to load. Defaults to 3.\n",
    "            init (int, optional): Integer given to the random seed. Defaults to 42.\n",
    "            verbose (bool, optional): Print the loaded files. Defaults to True\n",
    "\n",
    "        Raises:\n",
    "            Exception: Stop the process if n_pickles exceed pickle files number.\n",
    "\n",
    "        Returns:\n",
    "            obj: pd.Dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        # produce the pickles if the directory not exists or\n",
    "        # if the directory is empty \n",
    "        if (not os.path.exists(self.__out_path)) or \\\n",
    "              (len(os.listdir(self.__out_path)) == 0):\n",
    "            self.__produce_pickles()\n",
    "\n",
    "        pickle_files = [name for name in\n",
    "                        glob.glob(self.__out_path + \"/data_*.pkl\")]\n",
    "        # draw p_files        \n",
    "        seed(init)\n",
    "\n",
    "        if n_pickles <= 6:\n",
    "            random_p_files = sample(pickle_files, n_pickles)\n",
    "        else:\n",
    "            raise Exception(\"The parameter n_pickles (\" +\n",
    "                            \"{}) exceed the numbers of pickle files ({})\"\\\n",
    "                                .format(n_pickles, len(pickle_files)))\n",
    "        # print the drawed files\n",
    "        if verbose:\n",
    "            print(\"Loaded pickles:\")\n",
    "            for p in random_p_files:\n",
    "                print(p)\n",
    "\n",
    "        # load random pickles file\n",
    "        df_list = [pd.read_pickle(p) for p in random_p_files]\n",
    "\n",
    "        # create the dataframe by concatenate the previous\n",
    "        # dataframes list\n",
    "        df = pd.concat(df_list, ignore_index = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows number:  1000000\n"
     ]
    }
   ],
   "source": [
    "loader = Loader(in_path = './input/song_lyrics.csv', out_path = './data')\n",
    "df_orig = loader.load_pickle(1)\n",
    "print('Data rows number: ', len(df_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 1% of the dataset (10 000 songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows number:  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276826</th>\n",
       "      <td>Etap</td>\n",
       "      <td>rap</td>\n",
       "      <td>Der Plot</td>\n",
       "      <td>2014</td>\n",
       "      <td>124</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Part I - Conny:]\\nGuten Morgen fremdes Bett, ...</td>\n",
       "      <td>383522</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849425</th>\n",
       "      <td>Toothpick</td>\n",
       "      <td>pop</td>\n",
       "      <td>Biting Elbows</td>\n",
       "      <td>2012</td>\n",
       "      <td>8873</td>\n",
       "      <td>{}</td>\n",
       "      <td>Some folks got the patience of the angels\\nNot...</td>\n",
       "      <td>1166787</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504499</th>\n",
       "      <td>6 Feet Under</td>\n",
       "      <td>pop</td>\n",
       "      <td>Ana Johnsson</td>\n",
       "      <td>2004</td>\n",
       "      <td>60</td>\n",
       "      <td>{}</td>\n",
       "      <td>You just left me 6 feet under ground I'm burni...</td>\n",
       "      <td>803057</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601054</th>\n",
       "      <td>Ir Al Baile</td>\n",
       "      <td>pop</td>\n",
       "      <td>Onda Vaga</td>\n",
       "      <td>2015</td>\n",
       "      <td>731</td>\n",
       "      <td>{}</td>\n",
       "      <td>Cuando a los doce llevé la bandera en el hombr...</td>\n",
       "      <td>905848</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980221</th>\n",
       "      <td>Prudenza mai</td>\n",
       "      <td>pop</td>\n",
       "      <td>Ivan Graziani</td>\n",
       "      <td>1989</td>\n",
       "      <td>35</td>\n",
       "      <td>{}</td>\n",
       "      <td>Prudenza mai, mai...\\nMai neanche da bambino\\n...</td>\n",
       "      <td>1304379</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag         artist  year  views features  \\\n",
       "276826          Etap  rap       Der Plot  2014    124       {}   \n",
       "849425     Toothpick  pop  Biting Elbows  2012   8873       {}   \n",
       "504499  6 Feet Under  pop   Ana Johnsson  2004     60       {}   \n",
       "601054   Ir Al Baile  pop      Onda Vaga  2015    731       {}   \n",
       "980221  Prudenza mai  pop  Ivan Graziani  1989     35       {}   \n",
       "\n",
       "                                                   lyrics       id  \\\n",
       "276826  [Part I - Conny:]\\nGuten Morgen fremdes Bett, ...   383522   \n",
       "849425  Some folks got the patience of the angels\\nNot...  1166787   \n",
       "504499  You just left me 6 feet under ground I'm burni...   803057   \n",
       "601054  Cuando a los doce llevé la bandera en el hombr...   905848   \n",
       "980221  Prudenza mai, mai...\\nMai neanche da bambino\\n...  1304379   \n",
       "\n",
       "       language_cld3 language_ft language  \n",
       "276826            de          de       de  \n",
       "849425            en          en       en  \n",
       "504499            en          en       en  \n",
       "601054            es          es       es  \n",
       "980221            it          it       it  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_orig.sample(frac=0.01, random_state=1)\n",
    "print('Data rows number: ', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns and keep only english songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849425</th>\n",
       "      <td>Toothpick</td>\n",
       "      <td>pop</td>\n",
       "      <td>Biting Elbows</td>\n",
       "      <td>2012</td>\n",
       "      <td>Some folks got the patience of the angels\\nNot...</td>\n",
       "      <td>1166787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504499</th>\n",
       "      <td>6 Feet Under</td>\n",
       "      <td>pop</td>\n",
       "      <td>Ana Johnsson</td>\n",
       "      <td>2004</td>\n",
       "      <td>You just left me 6 feet under ground I'm burni...</td>\n",
       "      <td>803057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409364</th>\n",
       "      <td>The Poetaster Act 4. Scene 2</td>\n",
       "      <td>misc</td>\n",
       "      <td>Ben Jonson</td>\n",
       "      <td>1601</td>\n",
       "      <td>A Room in Lupus's House.\\n\\nEnter Lupus, HISTR...</td>\n",
       "      <td>674438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653769</th>\n",
       "      <td>Hes Gone</td>\n",
       "      <td>pop</td>\n",
       "      <td>Phil Lesh &amp; Friends</td>\n",
       "      <td>2015</td>\n",
       "      <td>Rat in a drain ditch, caught on a limb, you kn...</td>\n",
       "      <td>961823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846412</th>\n",
       "      <td>Ill Never Say</td>\n",
       "      <td>pop</td>\n",
       "      <td>Helen Ward</td>\n",
       "      <td>2015</td>\n",
       "      <td>I'll never say \"never again\" again\\nCause here...</td>\n",
       "      <td>1163619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54592</th>\n",
       "      <td>Fastest Rap Song</td>\n",
       "      <td>rap</td>\n",
       "      <td>Bone Thugs-N-Harmony</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yeah. runaway statue. Here we gooooo\\n\\nWay 2 ...</td>\n",
       "      <td>58074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581240</th>\n",
       "      <td>The Sleepless Sailor</td>\n",
       "      <td>pop</td>\n",
       "      <td>Kate Rusby</td>\n",
       "      <td>1999</td>\n",
       "      <td>I once was a sailor, a young man and brave\\nDa...</td>\n",
       "      <td>885191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662322</th>\n",
       "      <td>Locked</td>\n",
       "      <td>pop</td>\n",
       "      <td>Scritti Politti</td>\n",
       "      <td>2006</td>\n",
       "      <td>And when the day is done\\nIt's little games ar...</td>\n",
       "      <td>970831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639271</th>\n",
       "      <td>Valvoline</td>\n",
       "      <td>pop</td>\n",
       "      <td>Scout Niblett</td>\n",
       "      <td>2005</td>\n",
       "      <td>I am a driver\\nI am a driver\\nI am a driver\\nI...</td>\n",
       "      <td>946730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175434</th>\n",
       "      <td>Please Remember Me</td>\n",
       "      <td>country</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1999</td>\n",
       "      <td>[Verse 1]\\nWhen all our tears have reached the...</td>\n",
       "      <td>190652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7810 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title      tag                artist  year  \\\n",
       "849425                     Toothpick      pop         Biting Elbows  2012   \n",
       "504499                  6 Feet Under      pop          Ana Johnsson  2004   \n",
       "409364  The Poetaster Act 4. Scene 2     misc            Ben Jonson  1601   \n",
       "653769                      Hes Gone      pop   Phil Lesh & Friends  2015   \n",
       "846412                 Ill Never Say      pop            Helen Ward  2015   \n",
       "...                              ...      ...                   ...   ...   \n",
       "54592               Fastest Rap Song      rap  Bone Thugs-N-Harmony  2011   \n",
       "581240          The Sleepless Sailor      pop            Kate Rusby  1999   \n",
       "662322                        Locked      pop       Scritti Politti  2006   \n",
       "639271                     Valvoline      pop         Scout Niblett  2005   \n",
       "175434            Please Remember Me  country            Tim McGraw  1999   \n",
       "\n",
       "                                                   lyrics       id  \n",
       "849425  Some folks got the patience of the angels\\nNot...  1166787  \n",
       "504499  You just left me 6 feet under ground I'm burni...   803057  \n",
       "409364  A Room in Lupus's House.\\n\\nEnter Lupus, HISTR...   674438  \n",
       "653769  Rat in a drain ditch, caught on a limb, you kn...   961823  \n",
       "846412  I'll never say \"never again\" again\\nCause here...  1163619  \n",
       "...                                                   ...      ...  \n",
       "54592   Yeah. runaway statue. Here we gooooo\\n\\nWay 2 ...    58074  \n",
       "581240  I once was a sailor, a young man and brave\\nDa...   885191  \n",
       "662322  And when the day is done\\nIt's little games ar...   970831  \n",
       "639271  I am a driver\\nI am a driver\\nI am a driver\\nI...   946730  \n",
       "175434  [Verse 1]\\nWhen all our tears have reached the...   190652  \n",
       "\n",
       "[7810 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider only english songs\n",
    "df = df[df.language == 'en']\n",
    "df = df.dropna()\n",
    "df = df.drop(['language_cld3', 'language_ft','language','features','views'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alessandro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849425</th>\n",
       "      <td>Toothpick</td>\n",
       "      <td>pop</td>\n",
       "      <td>Biting Elbows</td>\n",
       "      <td>2012</td>\n",
       "      <td>Some folks got the patience of the angels\\nNot...</td>\n",
       "      <td>1166787</td>\n",
       "      <td>[folk, got, patience, angel, heart, well, year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504499</th>\n",
       "      <td>6 Feet Under</td>\n",
       "      <td>pop</td>\n",
       "      <td>Ana Johnsson</td>\n",
       "      <td>2004</td>\n",
       "      <td>You just left me 6 feet under ground I'm burni...</td>\n",
       "      <td>803057</td>\n",
       "      <td>[left, foot, ground, burning, sight, light, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409364</th>\n",
       "      <td>The Poetaster Act 4. Scene 2</td>\n",
       "      <td>misc</td>\n",
       "      <td>Ben Jonson</td>\n",
       "      <td>1601</td>\n",
       "      <td>A Room in Lupus's House.\\n\\nEnter Lupus, HISTR...</td>\n",
       "      <td>674438</td>\n",
       "      <td>[room, lupus, house, enter, lupus, histrio, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653769</th>\n",
       "      <td>Hes Gone</td>\n",
       "      <td>pop</td>\n",
       "      <td>Phil Lesh &amp; Friends</td>\n",
       "      <td>2015</td>\n",
       "      <td>Rat in a drain ditch, caught on a limb, you kn...</td>\n",
       "      <td>961823</td>\n",
       "      <td>[rat, drain, ditch, caught, limb, know, better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846412</th>\n",
       "      <td>Ill Never Say</td>\n",
       "      <td>pop</td>\n",
       "      <td>Helen Ward</td>\n",
       "      <td>2015</td>\n",
       "      <td>I'll never say \"never again\" again\\nCause here...</td>\n",
       "      <td>1163619</td>\n",
       "      <td>['ll, never, say, never, cause, love, head, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54592</th>\n",
       "      <td>Fastest Rap Song</td>\n",
       "      <td>rap</td>\n",
       "      <td>Bone Thugs-N-Harmony</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yeah. runaway statue. Here we gooooo\\n\\nWay 2 ...</td>\n",
       "      <td>58074</td>\n",
       "      <td>[runaway, statue, gooooo, way, strong-bizzy, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581240</th>\n",
       "      <td>The Sleepless Sailor</td>\n",
       "      <td>pop</td>\n",
       "      <td>Kate Rusby</td>\n",
       "      <td>1999</td>\n",
       "      <td>I once was a sailor, a young man and brave\\nDa...</td>\n",
       "      <td>885191</td>\n",
       "      <td>[sailor, young, man, brave, dum, day, dum, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662322</th>\n",
       "      <td>Locked</td>\n",
       "      <td>pop</td>\n",
       "      <td>Scritti Politti</td>\n",
       "      <td>2006</td>\n",
       "      <td>And when the day is done\\nIt's little games ar...</td>\n",
       "      <td>970831</td>\n",
       "      <td>[day, done, little, game, lost, maybe, 'll, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639271</th>\n",
       "      <td>Valvoline</td>\n",
       "      <td>pop</td>\n",
       "      <td>Scout Niblett</td>\n",
       "      <td>2005</td>\n",
       "      <td>I am a driver\\nI am a driver\\nI am a driver\\nI...</td>\n",
       "      <td>946730</td>\n",
       "      <td>[driver, driver, driver, driver, driver, drive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175434</th>\n",
       "      <td>Please Remember Me</td>\n",
       "      <td>country</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>1999</td>\n",
       "      <td>[Verse 1]\\nWhen all our tears have reached the...</td>\n",
       "      <td>190652</td>\n",
       "      <td>[tear, reached, sea, part, live, way, deep, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7810 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title      tag                artist  year  \\\n",
       "849425                     Toothpick      pop         Biting Elbows  2012   \n",
       "504499                  6 Feet Under      pop          Ana Johnsson  2004   \n",
       "409364  The Poetaster Act 4. Scene 2     misc            Ben Jonson  1601   \n",
       "653769                      Hes Gone      pop   Phil Lesh & Friends  2015   \n",
       "846412                 Ill Never Say      pop            Helen Ward  2015   \n",
       "...                              ...      ...                   ...   ...   \n",
       "54592               Fastest Rap Song      rap  Bone Thugs-N-Harmony  2011   \n",
       "581240          The Sleepless Sailor      pop            Kate Rusby  1999   \n",
       "662322                        Locked      pop       Scritti Politti  2006   \n",
       "639271                     Valvoline      pop         Scout Niblett  2005   \n",
       "175434            Please Remember Me  country            Tim McGraw  1999   \n",
       "\n",
       "                                                   lyrics       id  \\\n",
       "849425  Some folks got the patience of the angels\\nNot...  1166787   \n",
       "504499  You just left me 6 feet under ground I'm burni...   803057   \n",
       "409364  A Room in Lupus's House.\\n\\nEnter Lupus, HISTR...   674438   \n",
       "653769  Rat in a drain ditch, caught on a limb, you kn...   961823   \n",
       "846412  I'll never say \"never again\" again\\nCause here...  1163619   \n",
       "...                                                   ...      ...   \n",
       "54592   Yeah. runaway statue. Here we gooooo\\n\\nWay 2 ...    58074   \n",
       "581240  I once was a sailor, a young man and brave\\nDa...   885191   \n",
       "662322  And when the day is done\\nIt's little games ar...   970831   \n",
       "639271  I am a driver\\nI am a driver\\nI am a driver\\nI...   946730   \n",
       "175434  [Verse 1]\\nWhen all our tears have reached the...   190652   \n",
       "\n",
       "                                              lyrics_proc  \n",
       "849425  [folk, got, patience, angel, heart, well, year...  \n",
       "504499  [left, foot, ground, burning, sight, light, fo...  \n",
       "409364  [room, lupus, house, enter, lupus, histrio, li...  \n",
       "653769  [rat, drain, ditch, caught, limb, know, better...  \n",
       "846412  ['ll, never, say, never, cause, love, head, he...  \n",
       "...                                                   ...  \n",
       "54592   [runaway, statue, gooooo, way, strong-bizzy, b...  \n",
       "581240  [sailor, young, man, brave, dum, day, dum, dee...  \n",
       "662322  [day, done, little, game, lost, maybe, 'll, cl...  \n",
       "639271  [driver, driver, driver, driver, driver, drive...  \n",
       "175434  [tear, reached, sea, part, live, way, deep, in...  \n",
       "\n",
       "[7810 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove \\n\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[,\\.!?]', '', text)\n",
    "    #removing text in square braquet\n",
    "    text = re.sub(r'\\[.*?\\]', ' ', text)\n",
    "    #removing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*',' ', text)\n",
    "    #removing bracket\n",
    "    text = re.sub(r'[()]', ' ', text)\n",
    "    # convert all words in lower case\n",
    "    text = text.lower()\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    new_stop_words = ['ooh','yeah','hey','whoa','woah', 'ohh', 'was', 'mmm', 'oooh','yah','yeh','mmm', 'hmm','deh','doh','jah','wa']\n",
    "    stop_words.extend(new_stop_words)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    #remove tokens with lenght < 3\n",
    "    final_tokens = [token for token in lemmatized_tokens if len(token) > 2 and not token.isnumeric()]\n",
    "\n",
    "    return final_tokens\n",
    "\n",
    "cleaned_text = df[\"lyrics\"].apply(preprocess_text)\n",
    "df[\"lyrics_proc\"] = cleaned_text\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say',\n",
       " 'hello',\n",
       " 'sweetest',\n",
       " 'melody',\n",
       " 'know',\n",
       " 'sound',\n",
       " 'angel',\n",
       " 'singing',\n",
       " 'soft',\n",
       " 'low',\n",
       " 'make',\n",
       " 'music',\n",
       " 'laughter',\n",
       " 'echo',\n",
       " 'breeze',\n",
       " 'hush',\n",
       " 'lark',\n",
       " 'thrush',\n",
       " 'tree',\n",
       " 'calm',\n",
       " 'wave',\n",
       " 'rush',\n",
       " 'sea',\n",
       " 'make',\n",
       " 'music',\n",
       " 'time',\n",
       " 'breathes',\n",
       " 'sigh',\n",
       " 'symphony',\n",
       " 'begin',\n",
       " 'every',\n",
       " 'time',\n",
       " 'say',\n",
       " 'goodbye',\n",
       " 'million',\n",
       " 'violin',\n",
       " 'start',\n",
       " 'cry',\n",
       " 'song',\n",
       " 'sad',\n",
       " 'meet',\n",
       " 'kiss',\n",
       " 'song',\n",
       " 'sweet',\n",
       " 'whether',\n",
       " 'far',\n",
       " 'away',\n",
       " 'near',\n",
       " 'make',\n",
       " 'music',\n",
       " 'hear',\n",
       " 'every',\n",
       " 'time',\n",
       " 'say',\n",
       " 'goodbye',\n",
       " 'million',\n",
       " 'violin',\n",
       " 'start',\n",
       " 'cry',\n",
       " 'song',\n",
       " 'sad',\n",
       " 'meet',\n",
       " 'kiss',\n",
       " 'song',\n",
       " 'sweet',\n",
       " 'whether',\n",
       " 'far',\n",
       " 'away',\n",
       " 'near',\n",
       " 'make',\n",
       " 'music',\n",
       " 'hear']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]['lyrics_proc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"song_lyrics_proc.csv\" ,header='true', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
